#!/usr/bin/env python3
"""
æµ‹è¯• LLM è¾“å‡ºæ¸…æ´—åŠŸèƒ½
"""

import re

def clean_llm_artifacts(text):
    """
    æ¸…ç† LLM è¾“å‡ºä¸­çš„æ¨ç†è¿‡ç¨‹ã€æ€è€ƒæ ‡ç­¾ç­‰æ— å…³å†…å®¹
    """
    if not text:
        return text
    
    original_text = text
    
    # 1. ç§»é™¤ <think>...</think> æ ‡ç­¾åŠå…¶å†…å®¹ï¼ˆDeepSeek R1ï¼‰
    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # 2. ç§»é™¤ <reasoning>...</reasoning> æ ‡ç­¾åŠå…¶å†…å®¹
    text = re.sub(r'<reasoning>.*?</reasoning>', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # 3. ç§»é™¤ <thought>...</thought> æ ‡ç­¾åŠå…¶å†…å®¹
    text = re.sub(r'<thought>.*?</thought>', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # 4. ç§»é™¤å¼€å¤´çš„æ¨ç†è¯´æ˜ï¼ˆå¸¸è§æ¨¡å¼ï¼‰
    # å…ˆå°è¯•åŒ¹é…åˆ°åˆ†éš”çº¿
    if '---' in text or '___' in text:
        reasoning_with_divider = [
            r'^.*?(?:Here\'s my reasoning|Let me think|My thought process|Thinking process):.*?(?=\n+---)',
            r'^.*?(?:I will translate|Let me translate|Translation process):.*?(?=\n+---)',
        ]
        for pattern in reasoning_with_divider:
            match = re.search(pattern, text, flags=re.DOTALL | re.IGNORECASE)
            if match:
                text = text[match.end():]
                # ç§»é™¤å¼€å¤´çš„ç©ºç™½è¡Œå’Œåˆ†éš”çº¿
                text = re.sub(r'^\s*\n+---+\s*\n+', '', text)
                break
    
    # å¦‚æœæ²¡æœ‰åˆ†éš”çº¿ï¼ŒåŒ¹é…åˆ°åŒæ¢è¡Œ
    if text.startswith(('Here', 'Let me', 'I will', 'My thought', 'Thinking')):
        reasoning_patterns = [
            r'^.*?(?:Here\'s my reasoning|Let me think|My thought process|Thinking process):.*?(?=\n\n)',
            r'^.*?(?:I will translate|Let me translate|Translation process):.*?(?=\n\n)',
        ]
        for pattern in reasoning_patterns:
            text = re.sub(pattern, '', text, flags=re.DOTALL | re.IGNORECASE)
            break
    
    # 5. å¦‚æœæœ‰æ˜ç¡®çš„ "Translation:" æ ‡è®°ï¼Œåªä¿ç•™å…¶åçš„å†…å®¹
    translation_markers = [
        r'^.*?Translation:\s*\n',
        r'^.*?ç¿»è¯‘ç»“æœ[ï¼š:]\s*\n',
        r'^.*?Translated text:\s*\n',
        r'^.*?Final translation:\s*\n',
    ]
    for marker in translation_markers:
        match = re.search(marker, text, flags=re.DOTALL | re.IGNORECASE)
        if match:
            text = text[match.end():]
            break
    
    # 6. ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„å¤§é‡ç©ºç™½
    text = text.strip()
    
    # 7. ç§»é™¤å¼€å¤´çš„ä»£ç å—æ ‡è®°ï¼ˆå¦‚æœè¢«åŒ…è£¹åœ¨ markdown ä»£ç å—ä¸­ï¼‰
    text = re.sub(r'^```(?:markdown|md|text)?\s*\n', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\n```\s*$', '', text)
    
    # 8. ç§»é™¤æœ«å°¾çš„æ€»ç»“æ€§è¯„è®ºï¼ˆå¸¸è§äºæŸäº›æ¨¡å‹ï¼‰
    summary_patterns = [
        r'\n---+\s*\n.*?(?:Note|Summary|Explanation):.*$',
        r'\n\n---+\s*\n.*$',  # åˆ†éš”çº¿åçš„æ‰€æœ‰å†…å®¹
    ]
    for pattern in summary_patterns:
        text = re.sub(pattern, '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # æœ€ç»ˆæ¸…ç†
    text = text.strip()
    
    # å¦‚æœæ¸…ç†åå†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­ï¼ˆå¯èƒ½è¯¯åˆ ï¼‰ï¼Œè¿”å›åŸæ–‡
    if len(text) < 50 and len(original_text) > 100:
        return original_text
    
    return text


# ============ æµ‹è¯•ç”¨ä¾‹ ============

def test_think_tags():
    """æµ‹è¯• <think> æ ‡ç­¾æ¸…ç†"""
    input_text = """<think>
è¿™æ˜¯ä¸€æœ¬å…³äºäººå·¥æ™ºèƒ½çš„æŠ€æœ¯ä¹¦ç±ã€‚æˆ‘éœ€è¦æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š
1. ä¿æŒä¸“ä¸šæœ¯è¯­çš„å‡†ç¡®æ€§
2. ç»´æŠ¤ä¸Šä¸‹æ–‡çš„è¿è´¯æ€§
</think>

# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚"""
    
    expected = """# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚"""
    
    result = clean_llm_artifacts(input_text)
    assert result == expected, f"Expected:\n{expected}\n\nGot:\n{result}"
    print("âœ… Test 1: <think> tags - PASSED")


def test_translation_marker():
    """æµ‹è¯• Translation: æ ‡è®°æ¸…ç†"""
    input_text = """I will translate this text from English to Chinese.

Translation:

# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚"""
    
    expected = """# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚"""
    
    result = clean_llm_artifacts(input_text)
    assert result == expected, f"Expected:\n{expected}\n\nGot:\n{result}"
    print("âœ… Test 2: Translation marker - PASSED")


def test_reasoning_prefix():
    """æµ‹è¯•æ¨ç†å‰ç¼€æ¸…ç†"""
    input_text = """Here's my reasoning:
This is a technical book about AI, so I need to maintain consistency...

---

# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚"""
    
    expected = """# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚"""
    
    result = clean_llm_artifacts(input_text)
    assert result == expected, f"Expected:\n{expected}\n\nGot:\n{result}"
    print("âœ… Test 3: Reasoning prefix - PASSED")


def test_markdown_code_block():
    """æµ‹è¯• Markdown ä»£ç å—æ¸…ç†"""
    input_text = """```markdown
# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚
```"""
    
    expected = """# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚"""
    
    result = clean_llm_artifacts(input_text)
    assert result == expected, f"Expected:\n{expected}\n\nGot:\n{result}"
    print("âœ… Test 4: Markdown code block - PASSED")


def test_summary_note():
    """æµ‹è¯•æœ«å°¾æ€»ç»“æ¸…ç†"""
    input_text = """# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚

---

Note: This translation maintains the formal tone and technical accuracy."""
    
    expected = """# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚"""
    
    result = clean_llm_artifacts(input_text)
    assert result == expected, f"Expected:\n{expected}\n\nGot:\n{result}"
    print("âœ… Test 5: Summary note - PASSED")


def test_clean_text():
    """æµ‹è¯•å¹²å‡€æ–‡æœ¬ï¼ˆæ— éœ€æ¸…ç†ï¼‰"""
    input_text = """# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚

åœ¨å¤ä»£å°åº¦æ•™æ–‡æœ¬ä¸­ï¼Œæˆ‘ä»¬å®‡å®™ä¸­çš„ç¬¬ä¸€ä¸ªäººç›åŠªè¢«è­¦å‘Šå³å°†åˆ°æ¥çš„æ´ªæ°´ã€‚"""
    
    result = clean_llm_artifacts(input_text)
    assert result == input_text, f"Expected:\n{input_text}\n\nGot:\n{result}"
    print("âœ… Test 6: Clean text - PASSED")


def test_chinese_translation_marker():
    """æµ‹è¯•ä¸­æ–‡ç¿»è¯‘æ ‡è®°æ¸…ç†"""
    input_text = """åˆ†æå®Œæˆã€‚

ç¿»è¯‘ç»“æœï¼š

# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚"""
    
    expected = """# å³å°†åˆ°æ¥çš„æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚"""
    
    result = clean_llm_artifacts(input_text)
    assert result == expected, f"Expected:\n{expected}\n\nGot:\n{result}"
    print("âœ… Test 7: Chinese translation marker - PASSED")


def test_safety_mechanism():
    """æµ‹è¯•å®‰å…¨æœºåˆ¶ï¼ˆé˜²æ­¢è¯¯åˆ ï¼‰"""
    input_text = "çŸ­å†…å®¹"
    
    result = clean_llm_artifacts(input_text)
    assert result == input_text, f"Expected:\n{input_text}\n\nGot:\n{result}"
    print("âœ… Test 8: Safety mechanism - PASSED")


def test_complex_case():
    """æµ‹è¯•å¤æ‚æƒ…å†µï¼ˆå¤šç§æ··åˆï¼‰"""
    input_text = """<think>
Let me analyze this carefully...
I need to maintain consistency with terminology.
</think>

Here's my reasoning:
This is chapter 1 of a technical book.

---

Translation:

```markdown
# ç¬¬ä¸€ç« ï¼šéåˆ¶æ˜¯ä¸å¯èƒ½çš„

## æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚
```"""
    
    expected = """# ç¬¬ä¸€ç« ï¼šéåˆ¶æ˜¯ä¸å¯èƒ½çš„

## æµªæ½®

å‡ ä¹æ¯ä¸ªæ–‡åŒ–éƒ½æœ‰æ´ªæ°´ç¥è¯ã€‚"""
    
    result = clean_llm_artifacts(input_text)
    assert result == expected, f"Expected:\n{expected}\n\nGot:\n{result}"
    print("âœ… Test 9: Complex case - PASSED")


# ============ è¿è¡Œæ‰€æœ‰æµ‹è¯• ============

if __name__ == '__main__':
    print("\nğŸ§ª Testing LLM Artifact Cleaning Function\n")
    print("=" * 60)
    
    try:
        test_think_tags()
        test_translation_marker()
        test_reasoning_prefix()
        test_markdown_code_block()
        test_summary_note()
        test_clean_text()
        test_chinese_translation_marker()
        test_safety_mechanism()
        test_complex_case()
        
        print("=" * 60)
        print("\nâœ… All tests PASSED! (9/9)\n")
        
    except AssertionError as e:
        print("=" * 60)
        print(f"\nâŒ Test FAILED:\n{e}\n")
        exit(1)
