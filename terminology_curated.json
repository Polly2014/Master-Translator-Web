{
  "proper_nouns": [
    "Mustafa Suleyman",
    "Demis Hassabis",
    "DeepMind",
    "Google",
    "OpenAI",
    "AlphaGo",
    "AlphaZero",
    "GPT",
    "BERT",
    "China",
    "United States",
    "Silicon Valley",
    "Stanford",
    "MIT",
    "Harvard",
    "Yuval Noah Harari",
    "Eric Schmidt",
    "Sam Altman",
    "Elon Musk",
    "Andrew Ng",
    "Geoffrey Hinton",
    "Yann LeCun",
    "Yoshua Bengio",
    "Microsoft",
    "Meta",
    "Facebook",
    "Amazon",
    "Tesla",
    "Anthropic",
    "Claude"
  ],
  "technical_terms": [
    "AI",
    "artificial intelligence",
    "machine learning",
    "deep learning",
    "neural network",
    "neural networks",
    "algorithm",
    "algorithms",
    "model",
    "models",
    "training",
    "inference",
    "transformer",
    "transformers",
    "attention",
    "attention mechanism",
    "backpropagation",
    "gradient descent",
    "convolutional",
    "recurrent",
    "reinforcement learning",
    "supervised learning",
    "unsupervised learning",
    "transfer learning",
    "few-shot learning",
    "language model",
    "language models",
    "LLM",
    "large language model",
    "AGI",
    "artificial general intelligence",
    "synthetic biology",
    "biotechnology",
    "CRISPR",
    "gene editing",
    "DNA",
    "RNA",
    "protein",
    "genome",
    "quantum computing",
    "quantum computer",
    "robotics",
    "automation",
    "exponential",
    "disruptive",
    "transformative"
  ],
  "key_concepts": [
    "containment",
    "proliferation",
    "wave",
    "coming wave",
    "dilemma",
    "grand bargain",
    "nation-state",
    "nation-states",
    "governance",
    "regulation",
    "catastrophic risk",
    "existential risk",
    "fragility amplifiers",
    "incentives"
  ]
}
